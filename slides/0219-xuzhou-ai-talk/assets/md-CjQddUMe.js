import{o as r,b as o,w as n,g as e,ad as t,v as m,x as i,T as a}from"./modules/vue-B4QAKlIR.js";import{I as x}from"./slidev/default-CVwbI38Z.js";import{u as c,f as p}from"./slidev/context-B-aIOMhn.js";import"./index-DrKhBKue.js";import"./modules/shiki-DVNyJe3i.js";const _={__name:"slides.md__slidev_23",setup(b){const{$clicksContext:d,$frontmatter:l}=c();return d.setup(),(u,s)=>(r(),o(x,m(i(a(p)(a(l),22))),{default:n(()=>[...s[0]||(s[0]=[e("h1",null,"GPT 训练全流程：Pre-training → Post-training",-1),e("h3",null,"从「会说话」到「说人话」再到「说有用的话」",-1),e("div",{class:"mt-3 flex justify-center items-stretch gap-2.5 max-w-4xl mx-auto"},[e("div",{class:"flex-1 rounded-xl border-2 border-rose-300 bg-rose-50/60 p-4"},[e("div",{class:"text-rose-600 font-bold text-base mb-1"},"Pre-training"),e("div",{class:"text-xs text-slate-500 mb-2"},"预训练"),e("div",{class:"space-y-1.5 text-xs text-slate-600"},[e("div",null,"海量无标注文本 · 自回归语言建模"),e("div",null,"数万亿 token · 数百亿到千亿参数"),e("div",{class:"rounded bg-rose-100 px-2 py-1 mt-2 text-rose-700 font-medium"},"= 博学但不受控的续写机器")])]),e("div",{class:"flex items-center text-xl text-slate-400"},"→"),e("div",{class:"flex-[2] rounded-xl border-2 border-indigo-300 bg-indigo-50/40 p-4"},[e("div",{class:"text-indigo-600 font-bold text-base mb-1"},[t("Post-training "),e("span",{class:"font-normal text-xs text-slate-400 ml-1"},"后训练")]),e("div",{class:"grid grid-cols-2 gap-2.5 mt-2"},[e("div",{class:"rounded-lg border border-emerald-200 bg-emerald-50/60 p-3"},[e("div",{class:"text-emerald-600 font-bold text-sm mb-1"},"SFT 指令微调"),e("div",{class:"space-y-1 text-xs text-slate-600"},[e("div",null,"人工编写「指令—回答」对"),e("div",null,"学会遵循用户意图"),e("div",{class:"rounded bg-emerald-100 px-2 py-0.5 mt-1.5 text-emerald-700 font-medium"},"「接话」→「完成任务」")])]),e("div",{class:"rounded-lg border border-amber-200 bg-amber-50/60 p-3"},[e("div",{class:"text-amber-600 font-bold text-sm mb-1"},"RL 强化学习对齐"),e("div",{class:"space-y-1 text-xs text-slate-600"},[e("div",null,[e("span",{class:"text-amber-600 font-medium"},"RLHF"),t("：奖励模型学习人类偏好")]),e("div",null,[e("span",{class:"text-amber-600 font-medium"},"RLVR"),t("：可验证奖励（数学/代码对错）")]),e("div",{class:"rounded bg-amber-100 px-2 py-0.5 mt-1.5 text-amber-700 font-medium"},"「完成任务」→「对齐人类价值」")])])])])],-1),e("div",{class:"mt-3 grid grid-cols-2 gap-3 max-w-3xl mx-auto text-[11px] text-slate-500"},[e("div",{class:"rounded-md bg-slate-50 border border-slate-100 px-3 py-1.5 text-center"},[e("span",{class:"text-amber-500 font-semibold"},"RLHF"),t(" — 人类标注偏好排序 → 训练奖励模型 → PPO 优化｜适合"),e("span",{class:"font-medium text-slate-600"},"开放式任务")]),e("div",{class:"rounded-md bg-slate-50 border border-slate-100 px-3 py-1.5 text-center"},[e("span",{class:"text-amber-500 font-semibold"},"RLVR"),t(" — 规则判定对/错作为奖励信号｜适合"),e("span",{class:"font-medium text-slate-600"},"数学、代码等可验证任务"),t("（如 DeepSeek R1） ")])],-1),e("div",{class:"mt-3 text-center text-sm text-slate-600"},[t(" 三阶段的本质："),e("span",{class:"text-rose-500 font-medium"},"通用能力"),t(" → "),e("span",{class:"text-emerald-500 font-medium"},"任务遵循"),t(" → "),e("span",{class:"text-amber-500 font-medium"},"价值对齐"),t("　｜　从「每任务一模型」→「"),e("span",{class:"text-indigo-600 font-semibold"},"一个大模型 + 不同提示完成不同任务"),t("」 ")],-1)])]),_:1},16))}};export{_ as default};
