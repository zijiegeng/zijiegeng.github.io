import{o as n,b as r,w as o,g as s,ad as e,v as m,x as p,T as a}from"./modules/vue-DdBzI6iR.js";import{I as x}from"./slidev/default-DMjDit6e.js";import{u as c,f as i}from"./slidev/context-QOEjJLWk.js";import"./index-By41BRkw.js";import"./modules/shiki-DKM40GFB.js";const k={__name:"slides.md__slidev_14",setup(u){const{$clicksContext:l,$frontmatter:d}=c();return l.setup(),(g,t)=>(n(),r(x,m(p(a(i)(a(d),13))),{default:o(()=>[...t[0]||(t[0]=[s("h1",null,"从浅层到深层：为什么需要深度神经网络？",-1),s("h3",null,"如果把多个线性函数叠加起来会怎样？",-1),s("div",{class:"mt-3 flex justify-center items-center gap-2 text-sm"},[s("span",{class:"rounded bg-slate-100 px-3 py-1.5"},"x"),s("span",{class:"text-slate-400"},"→"),s("span",{class:"rounded bg-slate-200 px-3 py-1.5"},"线性层₁"),s("span",{class:"text-slate-400"},"→"),s("span",{class:"rounded bg-slate-200 px-3 py-1.5"},"线性层₂"),s("span",{class:"text-slate-400"},"→"),s("span",{class:"rounded bg-slate-200 px-3 py-1.5"},"线性层₃"),s("span",{class:"text-slate-400"},"→"),s("span",{class:"rounded bg-slate-100 px-3 py-1.5"},"y")],-1),s("div",{class:"mt-2 text-xs text-rose-600 font-medium text-center"},"多层线性 = 一层线性（矩阵乘法可合并），表达力没有任何提升！",-1),s("div",{class:"mt-5 text-sm text-slate-600"},[s("span",{class:"text-emerald-600 font-bold"},"关键突破：激活函数"),e("——在每层之间插入"),s("span",{class:"font-medium text-emerald-700"},"非线性变换"),e("（如 ReLU、Sigmoid），打破线性限制。 ")],-1),s("div",{class:"mt-3 flex justify-center items-center gap-2 text-sm"},[s("span",{class:"rounded bg-slate-100 px-3 py-1.5"},"x"),s("span",{class:"text-emerald-500"},"→"),s("span",{class:"rounded bg-emerald-100 px-3 py-1.5"},"线性层₁"),s("span",{class:"text-emerald-500"},"→"),s("span",{class:"rounded bg-amber-100 px-2 py-1.5 text-amber-700 font-medium"},"σ"),s("span",{class:"text-emerald-500"},"→"),s("span",{class:"rounded bg-emerald-100 px-3 py-1.5"},"线性层₂"),s("span",{class:"text-emerald-500"},"→"),s("span",{class:"rounded bg-amber-100 px-2 py-1.5 text-amber-700 font-medium"},"σ"),s("span",{class:"text-emerald-500"},"→"),s("span",{class:"rounded bg-emerald-100 px-3 py-1.5"},"线性层₃"),s("span",{class:"text-emerald-500"},"→"),s("span",{class:"rounded bg-slate-100 px-3 py-1.5"},"y")],-1),s("div",{class:"mt-2 text-xs text-emerald-600 font-medium text-center"},"线性层 + 非线性激活 = 深度神经网络 → 理论上可逼近任意连续函数（万能近似定理）",-1),s("div",{class:"mt-5 grid grid-cols-2 gap-5 max-w-4xl mx-auto text-sm"},[s("div",{class:"rounded-lg border-2 border-slate-200 bg-slate-50/50 p-3"},[s("div",{class:"text-slate-700 font-bold"},"统计 ML（浅层）"),s("div",{class:"mt-1 text-xs text-slate-600"},[e("数据 → "),s("span",{class:"text-amber-600 font-medium"},"[人工特征工程]"),e(" → 浅层模型 → 输出")]),s("div",{class:"mt-1 text-xs text-slate-500"},"特征要靠人设计，模型容量有限")]),s("div",{class:"rounded-lg border-2 border-emerald-200 bg-emerald-50/50 p-3"},[s("div",{class:"text-emerald-700 font-bold"},"深度学习（多层）"),s("div",{class:"mt-1 text-xs text-slate-600"},[e("数据 → "),s("span",{class:"text-emerald-600 font-medium"},"[可学习的深层神经网络]"),e(" → 输出")]),s("div",{class:"mt-1 text-xs text-slate-500"},"特征自动学习，端到端训练，容量可扩展")])],-1),s("div",{class:"mt-4 text-sm text-slate-600"},[s("span",{class:"text-indigo-600 font-medium"},"那么问题来了："),e("这么多层、这么多参数，怎么训练？答案仍然是梯度下降——只不过需要一个高效计算梯度的方法："),s("span",{class:"font-bold text-indigo-600"},"反向传播（Backpropagation）"),e("。 ")],-1),s("div",{class:"mt-3 rounded-lg bg-indigo-50/80 border-l-4 border-indigo-400 pl-3 py-2 text-xs text-slate-600"},[s("span",{class:"font-medium text-indigo-700"},"底层原理一脉相承："),e("从线性回归到深度网络，本质都是「"),s("span",{class:"font-medium"},"定义模型 → 定义损失 → 梯度下降优化参数"),e("」。深度学习的跃迁在于：模型从浅层线性变成深层非线性，表达力从有限到（近似）无限。 ")],-1)])]),_:1},16))}};export{k as default};
